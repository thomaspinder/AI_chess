{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess \n",
    "import chess.pgn\n",
    "import chess.polyglot\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "We'll first gather the data needed to train our neural network. Using LiChess' Database, we can collect 19.9 million real online chess games. The ratings of players on LiChess is approximately normally distributed with mean 1500, so we'll remove any games whereby one or more of the player's holds a GLICKO rating less than 2000 to ensure that we are only using data from *good* chess players.\n",
    "\n",
    "The board is represented within each game as a FEN string, so we'll need to parse that into a neural network friendly format. There are a number of ways of representing the board, however, we're going to keep things relatively simple here and represent the board as a a Zobrist Hash of the original board. The reseult of the game is just encoded as 1 for a white win, 2 for a black win and 3 for a draw; these values are purely arbitary as we'll one-hot encode them prior to training a network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "\n",
    "\n",
    "def parse_result(result):\n",
    "    if result == '1-0':\n",
    "        return 0\n",
    "    elif result == '1-0':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgn = open('data/2018_08.pgn')\n",
    "\n",
    "\n",
    "def get_notation():\n",
    "    result = {}\n",
    "    notation = list('eprnbqkPRNBQK')\n",
    "    i = 0\n",
    "    for piece in notation:\n",
    "        result[piece] = i\n",
    "        i += 1\n",
    "    return result\n",
    "\n",
    "def fen_expander(board_string, to_move_dict, notation_dict):\n",
    "    fen_string = board_string.split(' ')\n",
    "    # Get the next player to move\n",
    "    to_move = to_move_dict[fen_string[1]]\n",
    "    board_string = fen_string[0]\n",
    "    numbers = list(set(re.findall('\\d', board_string)))\n",
    "    for number in numbers:\n",
    "        board_string = board_string.replace(str(number), 'e' * int(number))\n",
    "    board_string = board_string.replace('/', '')\n",
    "    final_string = [notation_dict[x] for x in list(board_string)]\n",
    "    final_string.append(to_move)\n",
    "    return final_string\n",
    "\n",
    "\n",
    "def get_X_y(current_game, training_obj):\n",
    "    # Extract the current board\n",
    "    board = current_game.board()\n",
    "    # Parse and store the result\n",
    "    result = parse_result(current_game.headers['Result'])\n",
    "    training_obj.y.append([result] * len(list(current_game.main_line())))\n",
    "    # Get each board state of the game\n",
    "    for move in current_game.main_line():\n",
    "        board.push(move)\n",
    "        expanded_fen = fen_expander(board.fen(), to_move, notation_dict)\n",
    "        training_obj.X.append(expanded_fen)\n",
    "\n",
    "def nested_counter(item):\n",
    "    if type(item) == list:\n",
    "        return sum(nested_counter(subitem) for subitem in item)\n",
    "    else:\n",
    "        return 1\n",
    "        \n",
    "to_move = {'w': 0, 'b': 1}\n",
    "notation_dict = get_notation()\n",
    "\n",
    "i = 0\n",
    "max_games = 1000000\n",
    "max_training = 1000000\n",
    "board_states = []\n",
    "results = Training()\n",
    "\n",
    "start = time.time()\n",
    "while True and i < max_games and len(results.X)<max_training:\n",
    "    try:\n",
    "        game = chess.pgn.read_game(pgn)\n",
    "        if int(game.headers['BlackElo']) > 1500 and int(game.headers['WhiteElo']) > 1500:\n",
    "            get_X_y(game, results)\n",
    "    except (KeyboardInterrupt, SystemExit):\n",
    "        raise\n",
    "    i += 1\n",
    "\n",
    "with open('data/training_sma.obj', 'wb') as outfile:\n",
    "    pickle.dump(results, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the model\n",
    "\n",
    "We now have an object containing features are results so it's time to train the network. Although DeepMind use convolutional neural nets, we're just going to use a standard neural network with dropout layers to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Length: 1000082\n",
      "Label Length: 107\n"
     ]
    }
   ],
   "source": [
    "# Load object\n",
    "with open(r\"data/training_sma.obj\", \"rb\") as input_file:\n",
    "    data_obj = pickle.load(input_file)\n",
    "\n",
    "print('Feature Length: {}'.format(len(data_obj.X)))\n",
    "print('Label Length: {}'.format(len(data_obj.y[0])))\n",
    "\n",
    "# One-hot encode labels\n",
    "labels = [label for item in data_obj.y for label in item]\n",
    "labels_enc = to_categorical(np.array(labels))\n",
    "\n",
    "# Put features into matrix form\n",
    "features = np.array(data_obj.X)\n",
    "\n",
    "# Split into test/train sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels_enc, test_size=0.25, random_state=123)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the models architecture defined, we just need to define the optimiser and loss function before we can train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ea7855afc67a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msub_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mX_tr_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_last_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mX_te_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_last_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "def build_cnn(input_dim, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Reshape( (1, 8, 8), input_shape = (64,)))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu',input_shape=(8,8, 1), data_format='channels_first'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_ann(input_dim, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 80, activation = \"relu\", input_dim = input_dim, kernel_initializer = \"normal\"))\n",
    "    model.add(Dense(units = 120, activation = \"relu\", kernel_initializer='normal'))\n",
    "    model.add(Dense(units = 80, activation = \"relu\", kernel_initializer='normal'))\n",
    "    model.add(Dense(units = num_classes, activation = \"softmax\", kernel_initializer='normal'))\n",
    "    model.compile(loss = keras.losses.categorical_crossentropy, \n",
    "                 optimizer=keras.optimizers.Adam(),\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def remove_last_column(matrix):\n",
    "    sub_matrix = np.delete(matrix, -1, axis =1)\n",
    "    return sub_matrix\n",
    "\n",
    "X_tr_cnn = remove_last_column(X_train)\n",
    "X_te_cnn = remove_last_column(X_test)\n",
    "\n",
    "# ann_model = build_ann(X_train.shape[1], y_train.shape[1])\n",
    "# ann_model.fit(X_train, y_train, epochs = 100, batch_size=64)\n",
    "# accuracy = ann_model.evaluate(X_test, y_test, verbose=0)\n",
    "# print('Accuracy: {}'.format(accuracy))\n",
    "\n",
    "cnn_model = build_cnn(X_train.shape[1], y_train.shape[1])\n",
    "cnn_model.fit(X_tr_cnn, y_train, epochs=20, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model.save('chess_ann.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750061, 65)\n",
      "(750061, 64)\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
